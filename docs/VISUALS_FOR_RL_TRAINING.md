
# VISUALS_FOR_RL_TRAINING.md
# üìä Visual Blueprints for Pok√©mon Red RL Training
### High‚Äëimpact visualizations for papers, slideshows, dashboards, and real‚Äëtime monitoring

This file contains a structured list of **ideal, publication‚Äëgrade visualizations** you can generate from your Pok√©mon Red RL training pipeline. Each section explains:

1. **What the visualization is**
2. **Why it is scientifically interesting**
3. **What it communicates in a paper or talk**
4. **A Codex‚Äëready implementation prompt**

Use this to build a full visualization module in `Daddy/visuals/`.

---

# 1. üó∫Ô∏è Global Map Occupancy Heatmap
### ‚ÄúWhere has the agent explored across the world?‚Äù

**Description:**  
Render a stitched map of Kanto and overlay a heatmap of visit frequency for each (x,y) location.

**Why interesting:**  
Shows spatial exploration behavior, escape from local minima, curriculum effects.

**Paper usage:**  
Exploration quality figure; curiosity ablation.

**Codex prompt:**  
> ‚ÄúCreate `plot_global_map_heatmap(occupancy_grid, map_asset)` using matplotlib. Overlay tile visitation counts on a stitched Kanto map. Save PNG + MP4.‚Äù

---

# 2. üåÄ Swarm Trajectory Visualization  
### ‚ÄúHow 32‚Äì128 vectorized envs move during training‚Äù

**Description:**  
At each global step, plot the position of each parallel environment over the map.

**Why interesting:**  
Shows exploration diversity and curriculum spread.

**Paper usage:**  
Stability and robustness of multi-env swarming.

**Codex prompt:**  
> ‚ÄúImplement `plot_swarm_positions(env_positions, map_asset)` rendering each env's location as a colored dot, optionally animated to MP4.‚Äù

---

# 3. üõ£Ô∏è Per‚ÄëEpisode Trajectory Overlay  
### ‚ÄúDetailed path taken by the agent in one episode‚Äù

**Description:**  
Draw a polyline on the regional map for a single episode.

**Why interesting:**  
Concrete policy behavior.

**Paper usage:**  
Side‚Äëby‚Äëside ‚Äòbefore training‚Äô vs ‚Äòafter training‚Äô trajectories.

**Codex prompt:**  
> ‚ÄúImplement `draw_episode_path(path_coords, map_asset)` exporting to MP4 or PNG.‚Äù

---

# 4. üß≠ Bayesian Milestone Posterior Timelines  
### ‚ÄúPosterior confidence in reaching badges / milestones‚Äù

**Description:**  
Plot Beta posterior means & credible intervals for each milestone over training.

**Why interesting:**  
Supports your Bayesian progress‚Äëmonitoring paper.

**Paper usage:**  
Posterior trajectories demonstrating monitoring effectiveness.

**Codex prompt:**  
> ‚ÄúImplement `plot_milestone_posteriors(posterior_history)` with shaded 95% intervals.‚Äù

---

# 5. üî• Exploration Frontier Map  
### ‚ÄúWhere is the agent still curious?‚Äù

**Description:**  
Heatmap of RND prediction error or novelty score per tile.

**Why interesting:**  
Shows agent‚Äôs active learning target zones.

**Paper usage:**  
Illustration of intrinsic reward shaping.

**Codex prompt:**  
> ‚ÄúImplement `plot_exploration_frontier(novelty_grid, map_asset)`.‚Äù

---

# 6. üéûÔ∏è Annotated Rollout Video (MP4 + GIF)
### ‚ÄúHigh‚Äëimpact visual for talks‚Äù

**Overlay options:**
- Current map & coordinates  
- Action selected  
- Q‚Äëvalue summary  
- Badge flags  
- Posterior milestone bars  
- Reward breakdown  

**Why interesting:**  
Super persuasive demo of agent behavior.

**Paper usage:**  
Supplemental videos for publication.

**Codex prompt:**  
> ‚ÄúExtend `video_utils.py` to overlay HUD elements on frames before encoding to MP4/GIF.‚Äù

---

# 7. üß© Representation Space Embedding (UMAP / PCA)
### ‚ÄúWhat states look like in embedding space‚Äù

**Description:**  
Project GRU/LSTM/SSM embeddings to 2D.

**Why interesting:**  
Shows hierarchical representation learning.

**Paper usage:**  
Demonstrates learned structure across cities, gyms, etc.

**Codex prompt:**  
> ‚ÄúImplement `plot_state_embeddings(embeddings, labels)` using PCA‚ÜíUMAP.‚Äù

---

# 8. üìâ Action‚ÄëEntropy Timeline  
### ‚ÄúIs the agent exploring or exploiting?‚Äù

**Description:**  
Entropy of action distribution (or Q‚Äëvalue softmax) over time.

**Why interesting:**  
Correlates with learning stability, collapse, or over‚Äëexploration.

**Paper usage:**  
Figure in training dynamics section.

**Codex prompt:**  
> ‚ÄúAdd `plot_action_entropy(entropy_series)`.‚Äù

---

# 9. üîÄ Curriculum Pathway Graph
### ‚ÄúHow the curriculum or savestates are structured‚Äù

**Description:**  
Nodes = savestate clusters. Edges = transition / sampling frequency.

**Why interesting:**  
Explains curriculum curriculum dynamics visually.

**Paper usage:**  
Ablation comparing curriculum vs no-curriculum.

**Codex prompt:**  
> ‚ÄúImplement `plot_curriculum_graph(graph_data)` using networkx.‚Äù

---

# 10. üß± Replay Buffer Composition Analysis  
### ‚ÄúWhat does the agent actually learn from?‚Äù

**Description:**  
Histogram of state categories in replay buffer:
- Overworld  
- Towns  
- Gyms  
- Menus  
- Battles  
- PokeCenters  

**Why interesting:**  
Shows dataset distribution & training bias.

**Paper usage:**  
Strong diagnostic plot.

**Codex prompt:**  
> ‚ÄúImplement `plot_buffer_state_distribution(buffer_stats)`.‚Äù

---

# 11. üß¨ Multi‚ÄëTimescale Dynamics Panel  
### ‚ÄúGRU, LSTM, and SSM internals side‚Äëby‚Äëside‚Äù

**Description:**  
Line charts of:
- GRU activations  
- LSTM cell states  
- SSM convolutional responses  

**Why interesting:**  
Explains interplay between short/medium/long temporal scales.

**Paper usage:**  
Architectural understanding figure.

**Codex prompt:**  
> ‚ÄúImplement `plot_recurrent_dynamics(hidden_logs)`.‚Äù

---

# 12. üéá Final Training Summary Poster  
### ‚ÄúOne figure to rule them all‚Äù

Combine:
- Global heatmap  
- Posterior timeline  
- Exploration frontier  
- Badge timing heatmap  
- Action entropy timeline  

**Paper usage:**  
Introductory or concluding illustration.

**Codex prompt:**  
> ‚ÄúImplement `create_training_summary_poster(figures...)` via matplotlib gridspec.‚Äù

---

# Quick commands: plot returns + Bayes posteriors from a run

1) Activate env and set paths:
```
source .venv/bin/activate
export PYTHONPATH="$PWD:$PWD/pokemonred_puffer:$PYTHONPATH"
```
2) Plot the latest run in `runs/` (returns + Bayes if `progress.csv` exists):
```
python scripts/plot_latest.py
```
3) Or specify a run dir explicitly:
```
python scripts/plot_latest.py --run runs/short10k
```
Outputs:
- `plot_returns.png` (episode returns or events-based rolling `r_total`)
- `plot_bayes.png` (posterior means per milestone)

# üìå How to Use This With Codex Max

Paste into Copilot Chat:

> ‚ÄúRead VISUALS_FOR_RL_TRAINING.md. Create a new folder `Daddy/visuals/` and generate function stubs for each visualization with TODO comments based on the descriptions.‚Äù

This will produce a full visualization suite scaffolded for your agent.
